{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Y_L(x):\n",
    "    return 0.5*(6*x-2)*(6*x-2)*math.sin(12*x-4)+10*(x-0.5)-5\n",
    "#     if (x<0.5):\n",
    "#         return (0.5*(6*x-2)*(6*x-2)*math.sin(12*x-4))+(10*(x-0.5))-5\n",
    "#     else:\n",
    "#         return 3+(0.5*(6*x-2)*(6*x-2)*math.sin(12*x-4))+(10*(x-0.5))-5\n",
    "\n",
    "def Y_H(x):\n",
    "    return (6*x-2)*(6*x-2)*math.sin(12*x-4)\n",
    "#     if (x<0.5):\n",
    "#         return 2*Y_L(x)-20*x+20\n",
    "#     else:\n",
    "#         return 4+2*Y_L(x)-20*x+20\n",
    "\n",
    "H_x = []\n",
    "H_y = []\n",
    "for i in range(0,100,1):\n",
    "    H_x.append(i/100)\n",
    "    H_y.append(Y_H(i/100))\n",
    "\n",
    "H_training_input = np.array([0,0.4,0.6,1])\n",
    "output_list = []\n",
    "for i in range(0,4,1):\n",
    "    output_list.append(Y_H(H_training_input[i]))\n",
    "\n",
    "H_training_output = np.asarray(output_list)\n",
    "\n",
    "# plt.plot(H_x,H_y,H_training_input,H_training_output,'ro')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Keras model\n",
    "# model =  Sequential()\n",
    "# model.add(Dense(20,activation = 'tanh',input_dim=1 ))\n",
    "# model.add(Dense(20,activation = 'tanh'))\n",
    "# model.add(Dense(20,activation = 'tanh'))\n",
    "# model.add(Dense(20,activation = 'tanh'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# Optimizer = optimizers.SGD(lr =1e-3)\n",
    "# from keras import losses\n",
    "# # loss=losses.mean_absolute_error\n",
    "# # loss = tf.losses.mean_squared_error(data_y, output)\n",
    "# # Optimizer  = tf.contrib.opt.ScipyOptimizerInterface('mean_absolute_error',method=\"L-BFGS-B\")\n",
    "# model.compile(optimizer=Optimizer,loss='mean_absolute_error',metrics=['mae'])\n",
    "\n",
    "# # training \n",
    "# history = model.fit(H_training_input,H_training_output,epochs=500,batch_size=8)\n",
    "# # model.save(\"Model_single_large_data1.h5\")\n",
    "\n",
    "# predict = []\n",
    "# predict.append(0.6)\n",
    "# print(model.predict(np.asarray(predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%run models_for_multi.ipynb\n",
    "# import models_for_multi as mfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 4, 1, 50, 1\n",
    "\n",
    "H_training_input1 = H_training_input.reshape((4,1))\n",
    "H_training_input2 = H_training_input1.transpose()\n",
    "\n",
    "H_training_output1 = H_training_output.reshape((4,1))\n",
    "H_training_output2 = H_training_output1.transpose()\n",
    "\n",
    "print(type(H_training_input),'###',H_training_input.shape,H_training_input2.shape)\n",
    "\n",
    "x1 = torch.from_numpy(H_training_input2).float()\n",
    "y1 = torch.from_numpy(H_training_output2).float()\n",
    "\n",
    "x = x1.t()\n",
    "y = y1.t()\n",
    "print(type(x),x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model by instantiating the class defined above\n",
    "# model = DynamicNet(D_in, H, D_out)\n",
    "model = DNN_HF(D_in, H, D_out)\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.2)\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=1e-3)\n",
    "\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    \n",
    "    def closure():  \n",
    "#         optimizer.zero_grad() \n",
    "#         y_pred = model(x)\n",
    "#         # Compute and print loss\n",
    "#         loss = criterion(y_pred, y)\n",
    "#         if(t%10 == 0):\n",
    "#             print(t, loss.item())\n",
    "#         # Zero gradients, perform a backward pass, and update the weights.\n",
    "        \n",
    "#         loss.backward()\n",
    "#         return loss\n",
    "#     optimizer.step(closure)\n",
    "           \n",
    "        y_pred = model(x)\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        if(t%10 == 0):\n",
    "            print(t, loss.item())\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = np.asarray(H_x)\n",
    "temp1 = temp.reshape((100,1))\n",
    "temp2 = temp1.transpose()\n",
    "print(temp2.shape)\n",
    "t1 = torch.FloatTensor(temp2)\n",
    "t = t1.t()\n",
    "prediction = model(t)\n",
    "\n",
    "plt.plot(H_x,H_y,H_training_input,H_training_output,'ro',H_x,prediction.tolist())\n",
    "plt.show()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model,'saved_models/HF_trial4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model2 = torch.load('saved_models/HF_trial3')\n",
    "# prediction2 = model2(t)\n",
    "\n",
    "\n",
    "# plt.plot(H_x,H_y,H_training_input,H_training_output,'ro',H_x,prediction2.tolist())\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sie] *",
   "language": "python",
   "name": "conda-env-sie-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
